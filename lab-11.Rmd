---
title: "Lab 11 - Grading the professor, Pt. 2"
author: "Olivia Zhang"
date: "05/14/2025"
output: github_document
---

## Load packages and data

```{r load-packages, message=FALSE}
library(tidyverse) 
library(tidymodels)
library(openintro)
```

## Exercise 1

```{r exercise1_code}
m_bty <- linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ bty_avg, data = evals)
tidy(m_bty)
glance(m_bty)$r.squared
glance(m_bty)$adj.r.squared
```

The linear model predicting average professor evaluation score from average beauty rating is: score = 3.88 + 0.0666*bty_avg

The R2 is 0.04, meaning that professors' beauty rating explains 4% of variance in the evaluation scores. 

The adjusted R2 is 0.03.

## Exercise 2
 
```{r exercise2_code}
m_bty_gen <- linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ bty_avg*gender, data = evals)
tidy(m_bty_gen)
glance(m_bty_gen)$r.squared
glance(m_bty_gen)$adj.r.squared
```

The linear model predicting average professor evaluation score from average beauty rating and gender is: score = 3.95 + 0.0306*bty_avg - 0.184*male + 0.0796*bty_avg*male

## Exercise 3

The intercept of m_bty_gen model is 3.95, meaning female professors who have an average beauty rating of 0 will have an evaluation score of 3.95 on average. 

The coefficient of bty_avg is 0.0306, meaning that for female professors, as the average beauty rating increases 1 unit, the average evaluation score increases 0.0306 

The coefficient of gender_male is 0.184, meaning that for professor whose beauty rating is 0, the average evaluation score of male professors is 0.184 lower than that of female professors.

The coefficient of the interaction term is 0.0796, meaning that the effect of beauty ratings on evaluation scores depends on gender.

## Exercise 4

The R2 is 0.07, meaning that the model m_bty_gen explains 7% of variance in the evaluation scores. 

## Exercise 5

For male professors, the equation is: score = 3.766 + 0.1102*bty_avg

## Exercise 6

For two professors who received the same beauty rating, female tends to have the higher course evaluation score than female.

Note: the direction change if the interaction term is not included.

## Exercise 7

Beauty ratings affect male professors (0.1102) more than female professors (0.0306).

## Exercise 8

```{r exercise8_code}
glance(m_bty_gen)$adj.r.squared > glance(m_bty)$adj.r.squared
```

The adjusted R2 is higher for m_bty_gen than for m_bty, meaning that adding gender is effectively explaining more variance in the evaluation score than beauty ratings alone.

## Exercise 9

Yes, the slope for bty_avg decreased from 0.0666 (m_bty model) to 0.0306 (m_bty_gen model).

## Exercise 10

```{r exercise10_code}
m_bty_rank <- linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ bty_avg*rank, data = evals)
tidy(m_bty_rank)
glance(m_bty_rank)$r.squared
glance(m_bty_rank)$adj.r.squared
```

The linear model predicting average professor evaluation score from average beauty rating and rank is: score = 4.10 + 0.0417*bty_avg - 0.0188*TenureTrack - 0.409*Tenured - 0.0264*bty_avg*TenureTrack + 0.0659*bty_avg*Tenured

Intercept: For teaching professors whose beauty rating is 0, their evaluation score is 4.10.

Coefficient for bty_avg: for teaching professors, as their beauty rating increases 1 unit, their evaluation score increases 0.0417 unit. 

Coefficient for TenureTrack: for professors whose beauty rating is 0, TenureTrack professors is rated 0.0188 lower than teaching professors. 

Coefficient for Tenured: for professors whose beauty rating is 0, Tenured professors is rated 0.409 lower than teaching professors. 

Coefficient for bty_avg*TenureTrack interaction: the effect on beauty rating on evaluation score depends on whether the professor is on a teaching track or tenure track. 

Coefficient for bty_avg*Tenured interaction: the effect on beauty rating on evaluation score depends on whether the professor is on a teaching track or already tenured. 

## Exercise 11

I would guess that cls_students on its own is probably not a good predictor, because class size itself doesn't tell us how many students completed the eval.

## Exercise 12

```{r exercise12_code}
m_cls_students <- linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ cls_students, data = evals)
tidy(m_cls_students)
glance(m_cls_students)$r.squared
glance(m_cls_students)$adj.r.squared
```

The p-value for cls_students is 0.577, indicating that cls_students by iteslf is not a good predictor of evaluation score.

## Exercise 13

I would not include cls_did_eval, because it is redundant (you can calculate this variable from cls_perc_eval and cls_students).

## Exercise 14

```{r exercise14_code}
m_full <- linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ rank + ethnicity + gender + language + age + cls_perc_eval + cls_students + cls_level + cls_profs + cls_credits + bty_avg, data = evals)
tidy(m_full)
glance(m_full)$r.squared
glance(m_full)$adj.r.squared
```

## Exercise 15

```{r exercise15_code}
m_final <- linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~  ethnicity + gender + language + age + cls_perc_eval + cls_students + cls_credits + bty_avg, data = evals)
tidy(m_final)
glance(m_final)$r.squared
glance(m_final)$adj.r.squared
```

Final linear model:
score = 3.39 + 0.204*ethnicity + 0.177*gender - 0.151*language - 0.00487*age + 0.00575*cls_perc_eval + 0.000407*cls_students + 0.523*cls_credits + 0.0619*bty_avg

## Exercise 16

The coefficient of ethnicity is 0.204, meaning that professors who are not minority are rated 0.204 higher than professors who are minority.

The coefficient of age is -0.00487, meaning as a professor's age increases 1 year, their eval rating decreases 0.00487 unit.

## Exercise 17

A professor who receive high evaluation at University of Texas at Austin is probably not a minority, a male, received education in an English institution, relatively young, and good looking. Also, they need to be teaching a one credit course with a lot of students completing the evaluations.

## Exercise 18

I think this conclusion can probably be applied to other institutions, because the predictors are common in creating biases in students' perception of professors and courses. However, since Texas is a deep red state, some of the biases may be alleviated in blue states.